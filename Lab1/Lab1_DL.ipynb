{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4de9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45883d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate inputs\n",
    "def generate_linear(n = 100):\n",
    "    pts = np.random.uniform(0, 1, (n, 2))\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for pt in pts:\n",
    "        inputs.append([pt[0], pt[1]])\n",
    "        if pt[0] > pt[1]:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "\n",
    "    return np.array(inputs), np.array(labels).reshape(n, 1)\n",
    "\n",
    "def generate_XOR_easy():\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(11):\n",
    "        inputs.append([0.1 * i, 0.1 * i])\n",
    "        labels.append(0)\n",
    "\n",
    "        if 0.1 * i == 0.5:\n",
    "            continue\n",
    "        \n",
    "        inputs.append([0.1 * i, 1 - 0.1 * i])\n",
    "        labels.append(1)\n",
    "\n",
    "    return np.array(inputs), np.array(labels).reshape(21, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08fbfe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def show_result(x, y, pred_y):\n",
    "    y = y.ravel()\n",
    "    pred_y = pred_y.ravel()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Ground truth\", fontsize = 18)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        if y[i] == 0:\n",
    "            plt.plot(x[i][0], x[i][1], 'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0], x[i][1], 'bo')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predict result\", fontsize = 18)\n",
    "    for i in range(x.shape[0]):\n",
    "        if pred_y[i] == 0:\n",
    "            plt.plot(x[i][0], x[i][1], 'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0], x[i][1], 'bo')\n",
    "    plt.show()\n",
    "\n",
    "def show_loss(loss, epoch, interval):\n",
    "    epochs = np.arange(0, interval + epoch, interval)\n",
    "    plt.plot(epochs, loss, 'r-o')\n",
    "    plt.title(\"Loss curve\", fontsize = 18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad83b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    sigmoid_vec = np.vectorize(lambda t: 1 / (1 + np.exp(-t)) if t > 0 else 1 - 1 / (1 + np.exp(t)))\n",
    "    return sigmoid_vec(x)\n",
    "# derivative of sigmoid function\n",
    "def derivative_sigmoid(x):\n",
    "    return np.multiply(x, 1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c12a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def show_result(x, y, pred_y):\n",
    "    y = y.ravel()\n",
    "    pred_y = pred_y.ravel()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Ground truth\", fontsize = 18)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        if y[i] == 0:\n",
    "            plt.plot(x[i][0], x[i][1], 'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0], x[i][1], 'bo')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Predict result\", fontsize = 18)\n",
    "    for i in range(x.shape[0]):\n",
    "        if pred_y[i] == 0:\n",
    "            plt.plot(x[i][0], x[i][1], 'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0], x[i][1], 'bo')\n",
    "    plt.show()\n",
    "\n",
    "def show_loss(loss, epoch, interval):\n",
    "    epochs = np.arange(0, interval + epoch, interval)\n",
    "    plt.plot(epochs, loss, 'r-o')\n",
    "    plt.title(\"Loss curve\", fontsize = 18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce8b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, n1, n2, lr=0.01, epochs=2000, interval=100, activation_fn = True):\n",
    "        self.epsilon = 1e-9\n",
    "        self.lr = lr\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.epochs = epochs\n",
    "        self.interval = interval\n",
    "        self.activation_fn = activation_fn\n",
    "        self.loss_arr = []\n",
    "        \n",
    "        self.input = np.random.rand(2, 1)\n",
    "        self.W1 = np.random.rand(n1, 2)\n",
    "        self.W2 = np.random.rand(n2, n1)\n",
    "        self.W3 = np.random.rand(1, n2)\n",
    "        self.H1 = np.random.rand(n1, 1)\n",
    "        self.H2 = np.random.rand(n2, 1)\n",
    "        self.H3 = np.random.rand(1, 1)\n",
    "        self.Z1 = np.random.rand(n1, 1)\n",
    "        self.Z2 = np.random.rand(n2, 1)\n",
    "        self.output = np.random.rand(1, 1)\n",
    "    \n",
    "    def loss_fn(self, y, pred_y):\n",
    "        '''cross-entropy'''\n",
    "        return -np.matmul(y.T, np.log(pred_y + self.epsilon)) - np.matmul((1-y).T, np.log(1 - pred_y + self.epsilon))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        self.H1 = np.matmul(self.W1, self.input)\n",
    "        if self.activation_fn:\n",
    "            self.Z1 = sigmoid(self.H1)\n",
    "        else:\n",
    "            self.Z1 = self.H1\n",
    "        self.H2 = np.matmul(self.W2, self.Z1)\n",
    "        if self.activation_fn:\n",
    "            self.Z2 = sigmoid(self.H2)\n",
    "        else:\n",
    "            self.Z2 = self.H2\n",
    "        self.H3 = np.matmul(self.W3, self.Z2)\n",
    "        # Last layer must use a sigmoid to constraint the output into (0, 1) interval for predictions\n",
    "        self.output = sigmoid(self.H3)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, y, pred_y):\n",
    "        Cost_to_predy = (1 - y) / (1 - pred_y + self.epsilon) - y / (pred_y + self.epsilon)\n",
    "        # Last layer must use a sigmoid to constraint the output into (0, 1) interval for predictions\n",
    "        predy_to_H3 = np.diag(derivative_sigmoid(self.output).reshape(-1))\n",
    "        H3_to_W3 = self.Z2.T\n",
    "        Cost_to_H3 = np.matmul(Cost_to_predy, predy_to_H3)\n",
    "        Cost_to_W3 = np.matmul(Cost_to_H3, H3_to_W3)\n",
    "\n",
    "        H3_to_Z2 = self.W3\n",
    "        if self.activation_fn:\n",
    "            Z2_to_H2 = np.diag(derivative_sigmoid(self.Z2).reshape(-1))\n",
    "        else:\n",
    "            Z2_to_H2 = np.identity(derivative_sigmoid(self.Z2).reshape(-1).shape[0])\n",
    "        H2_to_W2 = np.zeros((self.H2.shape[0], self.W2.shape[0] * self.W2.shape[1]))\n",
    "        n, m = self.H2.shape[0], self.W2.shape[1]\n",
    "        for i in range(n):\n",
    "            H2_to_W2[i, i * m: (i+1) * m] = self.Z1.reshape(-1)\n",
    "        Cost_to_H2 = np.linalg.multi_dot([Cost_to_H3, H3_to_Z2, Z2_to_H2])\n",
    "        Cost_to_W2 = np.matmul(Cost_to_H2, H2_to_W2)\n",
    "        Cost_to_W2 = Cost_to_W2.reshape(n, m)\n",
    "        \n",
    "        H2_to_Z1 = self.W2\n",
    "        if self.activation_fn:\n",
    "            Z1_to_H1 = np.diag(derivative_sigmoid(self.Z1).reshape(-1))\n",
    "        else:\n",
    "            Z1_to_H1 = np.identity(derivative_sigmoid(self.Z1).reshape(-1).shape[0])\n",
    "        H1_to_W1 = np.zeros((self.H1.shape[0], self.W1.shape[0] * self.W1.shape[1]))\n",
    "        n, m = self.H1.shape[0], self.W1.shape[1]\n",
    "        for i in range(n):\n",
    "            H1_to_W1[i, i * m: (i + 1) * m] = self.input.reshape(-1)\n",
    "        Cost_to_H1 = np.linalg.multi_dot([Cost_to_H2, H2_to_Z1, Z1_to_H1])\n",
    "        Cost_to_W1 = np.matmul(Cost_to_H1, H1_to_W1)\n",
    "        Cost_to_W1 = Cost_to_W1.reshape(n, m)\n",
    "        \n",
    "        self.W1 -= self.lr * Cost_to_W1\n",
    "        self.W2 -= self.lr * Cost_to_W2\n",
    "        self.W3 -= self.lr * Cost_to_W3\n",
    "        return\n",
    "        \n",
    "\n",
    "    def train(self, X, y):\n",
    "        for e in range(self.epochs):\n",
    "            if e == round(self.epochs / 2):\n",
    "                self.lr /= 2 # scheduler\n",
    "            for i in range(X.shape[0]):\n",
    "                self.output = self.forward(X[i: (i + 1), :].T)\n",
    "                self.backward(y[i: (i + 1), :], self.output)\n",
    "\n",
    "            if e % self.interval == 0:\n",
    "                print('Epochs {}: '.format(e), end = '')\n",
    "                self.test(X, y)\n",
    "\n",
    "        print('Training finished')\n",
    "        self.test(X, y)\n",
    "        show_loss(self.loss_arr, self.epochs, self.interval)\n",
    "\n",
    "    def test(self, X, y):     \n",
    "        error = 0.0\n",
    "        pred_y = np.zeros_like(y, dtype = float)\n",
    "        for i in range(X.shape[0]):\n",
    "            output = self.forward(X[i: (i + 1), :].T)\n",
    "            pred_y[i, 0] = output.item()\n",
    "            result = np.round(output)\n",
    "            error += abs(result - y[i: (i + 1), :])\n",
    "        error /= X.shape[0]\n",
    "        loss = self.loss_fn(y, pred_y)\n",
    "        self.loss_arr.append(loss[0][0])\n",
    "        print(f\"accuracy: {((1 - error) * 100)[0][0]:.2f}%, loss: {loss[0][0]:.5f}\")\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebc928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = \"linear\"\n",
    "'''for linear: use epochs = 1000 is enough, while for XOR, use epochs = 2500, since data size is smaller, need longer training'''\n",
    "epochs = 1000\n",
    "interval = 100\n",
    "'''lr to try: 0.01, 0.1, 1'''\n",
    "lr = 0.1\n",
    "'''number of neurons to try\n",
    "n1 = 5, n2 = 100 (small to big)\n",
    "n1 = 100, n2 = 5 (big to small)\n",
    "n1 = 5, n2 = 5 (small to small)\n",
    "n1 = 100, n2 = 100 (big to big)\n",
    "'''\n",
    "n1 = 10\n",
    "n2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1ffb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generator == \"linear\":\n",
    "    X, y = generate_linear(n = 100)\n",
    "elif generator == \"XOR\":\n",
    "    X, y = generate_XOR_easy()\n",
    "    # every data point in X is a row, [x, y]\n",
    "else:\n",
    "    raise NameError(\"Unknown data generator name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76ac671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_fn = True # turn on activation function or not\n",
    "# network = NN(n1, n2, lr, epochs, interval)\n",
    "# network.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9f4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = np.zeros_like(y)\n",
    "# for i in range(X.shape[0]):\n",
    "#     pred_y[i, 0] = np.round(network.forward(X[i: (i + 1), :].T))\n",
    "# show_result(X, y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbd23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_fn = False\n",
    "# network_no_act = NN(n1, n2, lr, epochs, interval, activation_fn)\n",
    "# network_no_act.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "661b707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = np.zeros_like(y)\n",
    "# for i in range(X.shape[0]):\n",
    "#     pred_y[i, 0] = np.round(network_no_act.forward(X[i: (i + 1), :].T))\n",
    "# show_result(X, y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "882687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "def derivative_ReLU(z):\n",
    "    return (z > 0.0) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a408a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_other_activation:\n",
    "    def __init__(self, n1, n2, lr=0.01, epochs=2000, interval=100, activation_fn = \"ReLU\"):\n",
    "        self.epsilon = 1e-9\n",
    "        self.lr = lr\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.epochs = epochs\n",
    "        self.interval = interval\n",
    "        self.activation_fn = activation_fn\n",
    "        self.loss_arr = []\n",
    "        \n",
    "        self.input = np.random.uniform(-1, 1, (2, 1))\n",
    "        self.W1 = np.random.uniform(-1, 1, (n1, 2))\n",
    "        self.W2 = np.random.uniform(-1, 1, (n2, n1))\n",
    "        self.W3 = np.random.uniform(-1, 1, (1, n2))\n",
    "        self.H1 = np.random.uniform(-1, 1, (n1, 1))\n",
    "        self.H2 = np.random.uniform(-1, 1, (n2, 1))\n",
    "        self.H3 = np.random.uniform(-1, 1, (1, 1))\n",
    "        self.Z1 = np.random.uniform(-1, 1, (n1, 1))\n",
    "        self.Z2 = np.random.uniform(-1, 1, (n2, 1))\n",
    "        self.output = np.random.uniform(-1, 1, (1, 1))\n",
    "    \n",
    "    def loss_fn(self, y, pred_y):\n",
    "        '''cross-entropy'''\n",
    "        return -np.matmul(y.T, np.log(pred_y + self.epsilon)) - np.matmul((1-y).T, np.log(1 - pred_y + self.epsilon))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        self.H1 = np.matmul(self.W1, self.input)\n",
    "        if self.activation_fn == 'ReLU':\n",
    "            self.Z1 = ReLU(self.H1)\n",
    "        else:\n",
    "            self.Z1 = self.H1\n",
    "        self.H2 = np.matmul(self.W2, self.Z1)\n",
    "        if self.activation_fn == 'ReLU':\n",
    "            self.Z2 = ReLU(self.H2)\n",
    "        else:\n",
    "            self.Z2 = self.H2\n",
    "        self.H3 = np.matmul(self.W3, self.Z2)\n",
    "        # Last layer must use a sigmoid to constraint the output into (0, 1) interval for predictions\n",
    "        self.output = sigmoid(self.H3)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, y, pred_y):\n",
    "        Cost_to_predy = (1 - y) / (1 - pred_y + self.epsilon) - y / (pred_y + self.epsilon)\n",
    "        # Last layer must use a sigmoid to constraint the output into (0, 1) interval for predictions\n",
    "        predy_to_H3 = np.diag(derivative_sigmoid(self.output).reshape(-1))\n",
    "        H3_to_W3 = self.Z2.T\n",
    "        Cost_to_H3 = np.matmul(Cost_to_predy, predy_to_H3)\n",
    "        Cost_to_W3 = np.matmul(Cost_to_H3, H3_to_W3)\n",
    "\n",
    "        H3_to_Z2 = self.W3\n",
    "        if self.activation_fn == 'ReLU':\n",
    "            Z2_to_H2 = np.diag(derivative_ReLU(self.Z2).reshape(-1))\n",
    "        else:\n",
    "            Z2_to_H2 = np.identity(derivative_ReLU(self.Z2).reshape(-1).shape[0])\n",
    "        H2_to_W2 = np.zeros((self.H2.shape[0], self.W2.shape[0] * self.W2.shape[1]))\n",
    "        n, m = self.H2.shape[0], self.W2.shape[1]\n",
    "        for i in range(n):\n",
    "            H2_to_W2[i, i * m: (i+1) * m] = self.Z1.reshape(-1)\n",
    "        Cost_to_H2 = np.linalg.multi_dot([Cost_to_H3, H3_to_Z2, Z2_to_H2])\n",
    "        Cost_to_W2 = np.matmul(Cost_to_H2, H2_to_W2)\n",
    "        Cost_to_W2 = Cost_to_W2.reshape(n, m)\n",
    "        \n",
    "        H2_to_Z1 = self.W2\n",
    "        if self.activation_fn == 'ReLU':\n",
    "            Z1_to_H1 = np.diag(derivative_ReLU(self.Z1).reshape(-1))\n",
    "        else:\n",
    "            Z1_to_H1 = np.identity(derivative_ReLU(self.Z1).reshape(-1).shape[0])\n",
    "        H1_to_W1 = np.zeros((self.H1.shape[0], self.W1.shape[0] * self.W1.shape[1]))\n",
    "        n, m = self.H1.shape[0], self.W1.shape[1]\n",
    "        for i in range(n):\n",
    "            H1_to_W1[i, i * m: (i + 1) * m] = self.input.reshape(-1)\n",
    "        Cost_to_H1 = np.linalg.multi_dot([Cost_to_H2, H2_to_Z1, Z1_to_H1])\n",
    "        Cost_to_W1 = np.matmul(Cost_to_H1, H1_to_W1)\n",
    "        Cost_to_W1 = Cost_to_W1.reshape(n, m)\n",
    "        \n",
    "        self.W1 -= self.lr * Cost_to_W1\n",
    "        self.W2 -= self.lr * Cost_to_W2\n",
    "        self.W3 -= self.lr * Cost_to_W3\n",
    "        return\n",
    "        \n",
    "\n",
    "    def train(self, X, y):\n",
    "        for e in range(self.epochs):\n",
    "            if e == round(self.epochs / 2):\n",
    "                self.lr /= 2 # scheduler\n",
    "            for i in range(X.shape[0]):\n",
    "                self.output = self.forward(X[i: (i + 1), :].T)\n",
    "                self.backward(y[i: (i + 1), :], self.output)\n",
    "\n",
    "            if e % self.interval == 0:\n",
    "                print('Epochs {}: '.format(e), end = '')\n",
    "                self.test(X, y)\n",
    "\n",
    "        print('Training finished')\n",
    "        self.test(X, y)\n",
    "        show_loss(self.loss_arr, self.epochs, self.interval)\n",
    "\n",
    "    def test(self, X, y):     \n",
    "        error = 0.0\n",
    "        pred_y = np.zeros_like(y, dtype = float)\n",
    "        for i in range(X.shape[0]):\n",
    "            output = self.forward(X[i: (i + 1), :].T)\n",
    "            pred_y[i, 0] = output.item()\n",
    "            result = np.round(output)\n",
    "            error += abs(result - y[i: (i + 1), :])\n",
    "        error /= X.shape[0]\n",
    "        loss = self.loss_fn(y, pred_y)\n",
    "        self.loss_arr.append(loss[0][0])\n",
    "        print(f\"accuracy: {((1 - error) * 100)[0][0]:.2f}%, loss: {loss[0][0]:.5f}\")\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a489c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = \"linear\"\n",
    "# epochs = 1000\n",
    "# interval = 100\n",
    "# lr = 0.1\n",
    "# n1 = 10\n",
    "# n2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9656bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if generator == \"linear\":\n",
    "#     X, y = generate_linear(n = 100)\n",
    "# elif generator == \"XOR\":\n",
    "#     X, y = generate_XOR_easy()\n",
    "#     # every data point in X is a row, [x, y]\n",
    "# else:\n",
    "#     raise NameError(\"Unknown data generator name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b6fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = NN_other_activation(n1, n2, lr, epochs, interval)\n",
    "# network.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f7d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = np.zeros_like(y)\n",
    "# for i in range(X.shape[0]):\n",
    "#     pred_y[i, 0] = np.round(network.forward(X[i: (i + 1), :].T))\n",
    "# show_result(X, y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be5841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam_optimizer():\n",
    "    def __init__(self, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-9):\n",
    "        self.grad_mean = 0\n",
    "        self.grad_var = 0 # uncentered\n",
    "        '''momentum'''\n",
    "        self.beta1 = beta1 # the exponential decay of the rate for first moment estimates\n",
    "        self.beta2 = beta2 # the exponential decay of the rate for second moment estimates\n",
    "        self.epsilon = epsilon # for not dividing from 0\n",
    "    def step(self, t, w, dw, lr):\n",
    "        # momentum beta 1\n",
    "        self.grad_mean = self.beta1 * self.grad_mean + (1 - self.beta1) * dw\n",
    "        # RMS beta 2\n",
    "        self.grad_var = self.beta2 * self.grad_var + (1 - self.beta2) * (dw ** 2)\n",
    "        # bias correction, for moving average based method (RMS)\n",
    "        grad_mean_corr = self.grad_mean / (1 - self.beta1 ** t)\n",
    "        grad_var_corr = self.grad_var / (1 - self.beta2 ** t)\n",
    "        \n",
    "        # update\n",
    "        w -= lr * (grad_mean_corr / (np.sqrt(grad_var_corr) + self.epsilon))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d96aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_optimizer:\n",
    "    def __init__(self, n1, n2, lr=0.01, epochs=2000, interval=100, activation_fn = True, optimizers = None):\n",
    "        self.epsilon = 1e-9\n",
    "        self.lr = lr\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.epochs = epochs\n",
    "        self.interval = interval\n",
    "        self.activation_fn = activation_fn\n",
    "        self.optimizers = optimizers\n",
    "        if optimizers != None:\n",
    "            assert len(optimizers) == 3 # 3 different optimizers for 3 weight matrixes\n",
    "        self.t = 1\n",
    "        self.loss_arr = []\n",
    "        \n",
    "        self.input = np.random.rand(2, 1)\n",
    "        self.W1 = np.random.rand(n1, 2)\n",
    "        self.W2 = np.random.rand(n2, n1)\n",
    "        self.W3 = np.random.rand(1, n2)\n",
    "        self.H1 = np.random.rand(n1, 1)\n",
    "        self.H2 = np.random.rand(n2, 1)\n",
    "        self.H3 = np.random.rand(1, 1)\n",
    "        self.Z1 = np.random.rand(n1, 1)\n",
    "        self.Z2 = np.random.rand(n2, 1)\n",
    "        self.output = np.random.rand(1, 1)\n",
    "    \n",
    "    def loss_fn(self, y, pred_y):\n",
    "        '''cross-entropy'''\n",
    "        return np.absolute(-np.matmul(y.T, np.log(pred_y + self.epsilon)) - np.matmul((1-y).T, np.log(1 - pred_y + self.epsilon)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input = X\n",
    "        self.H1 = np.matmul(self.W1, self.input)\n",
    "        if self.activation_fn:\n",
    "            self.Z1 = sigmoid(self.H1)\n",
    "        else:\n",
    "            self.Z1 = self.H1\n",
    "        self.H2 = np.matmul(self.W2, self.Z1)\n",
    "        if self.activation_fn:\n",
    "            self.Z2 = sigmoid(self.H2)\n",
    "        else:\n",
    "            self.Z2 = self.H2\n",
    "        self.H3 = np.matmul(self.W3, self.Z2)\n",
    "        # Last layer must use a sigmoid to constraint the output into (0, 1) interval for predictions\n",
    "        self.output = sigmoid(self.H3)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, y, pred_y, t):\n",
    "        Cost_to_predy = (1 - y) / (1 - pred_y + self.epsilon) - y / (pred_y + self.epsilon)\n",
    "        # Last layer must use a sigmoid to constraint the output into (0, 1) interval for predictions\n",
    "        predy_to_H3 = np.diag(derivative_sigmoid(self.output).reshape(-1))\n",
    "        H3_to_W3 = self.Z2.T\n",
    "        Cost_to_H3 = np.matmul(Cost_to_predy, predy_to_H3)\n",
    "        Cost_to_W3 = np.matmul(Cost_to_H3, H3_to_W3)\n",
    "\n",
    "        H3_to_Z2 = self.W3\n",
    "        if self.activation_fn:\n",
    "            Z2_to_H2 = np.diag(derivative_sigmoid(self.Z2).reshape(-1))\n",
    "        else:\n",
    "            Z2_to_H2 = np.identity(derivative_sigmoid(self.Z2).reshape(-1).shape[0])\n",
    "        H2_to_W2 = np.zeros((self.H2.shape[0], self.W2.shape[0] * self.W2.shape[1]))\n",
    "        n, m = self.H2.shape[0], self.W2.shape[1]\n",
    "        for i in range(n):\n",
    "            H2_to_W2[i, i * m: (i+1) * m] = self.Z1.reshape(-1)\n",
    "        Cost_to_H2 = np.linalg.multi_dot([Cost_to_H3, H3_to_Z2, Z2_to_H2])\n",
    "        Cost_to_W2 = np.matmul(Cost_to_H2, H2_to_W2)\n",
    "        Cost_to_W2 = Cost_to_W2.reshape(n, m)\n",
    "        \n",
    "        H2_to_Z1 = self.W2\n",
    "        if self.activation_fn:\n",
    "            Z1_to_H1 = np.diag(derivative_sigmoid(self.Z1).reshape(-1))\n",
    "        else:\n",
    "            Z1_to_H1 = np.identity(derivative_sigmoid(self.Z1).reshape(-1).shape[0])\n",
    "        H1_to_W1 = np.zeros((self.H1.shape[0], self.W1.shape[0] * self.W1.shape[1]))\n",
    "        n, m = self.H1.shape[0], self.W1.shape[1]\n",
    "        for i in range(n):\n",
    "            H1_to_W1[i, i * m: (i + 1) * m] = self.input.reshape(-1)\n",
    "        Cost_to_H1 = np.linalg.multi_dot([Cost_to_H2, H2_to_Z1, Z1_to_H1])\n",
    "        Cost_to_W1 = np.matmul(Cost_to_H1, H1_to_W1)\n",
    "        Cost_to_W1 = Cost_to_W1.reshape(n, m)\n",
    "        \n",
    "        if self.optimizers:\n",
    "            self.W1 = self.optimizers[0].step(t, self.W1, Cost_to_W1, self.lr)\n",
    "            self.W2 = self.optimizers[1].step(t, self.W2, Cost_to_W2, self.lr)\n",
    "            self.W3 = self.optimizers[2].step(t, self.W3, Cost_to_W3, self.lr)\n",
    "        else:\n",
    "            self.W1 -= self.lr * Cost_to_W1\n",
    "            self.W2 -= self.lr * Cost_to_W2\n",
    "            self.W3 -= self.lr * Cost_to_W3\n",
    "        return\n",
    "        \n",
    "\n",
    "    def train(self, X, y):\n",
    "        for e in range(self.epochs):\n",
    "            if e == round(self.epochs / 2):\n",
    "                self.lr /= 2 # scheduler\n",
    "            for i in range(X.shape[0]):\n",
    "                self.output = self.forward(X[i: (i + 1), :].T)\n",
    "                self.backward(y[i: (i + 1), :], self.output, self.t)\n",
    "                self.t += 1\n",
    "\n",
    "            if e % self.interval == 0:\n",
    "                print('Epochs {}: '.format(e), end = '')\n",
    "                self.test(X, y)\n",
    "\n",
    "        print('Training finished')\n",
    "        self.test(X, y)\n",
    "        show_loss(self.loss_arr, self.epochs, self.interval)\n",
    "\n",
    "    def test(self, X, y):     \n",
    "        error = 0.0\n",
    "        pred_y = np.zeros_like(y, dtype = float)\n",
    "        for i in range(X.shape[0]):\n",
    "            output = self.forward(X[i: (i + 1), :].T)\n",
    "            pred_y[i, 0] = output.item()\n",
    "            result = np.round(output)\n",
    "            error += abs(result - y[i: (i + 1), :])\n",
    "        error /= X.shape[0]\n",
    "        loss = self.loss_fn(y, pred_y)\n",
    "        self.loss_arr.append(loss[0][0])\n",
    "        print(f\"accuracy: {((1 - error) * 100)[0][0]:.2f}%, loss: {loss[0][0]:.5f}\")\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3cdedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = \"linear\"\n",
    "epochs = 1000\n",
    "interval = 100\n",
    "lr = 0.1\n",
    "n1 = 10\n",
    "n2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfc36503",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generator == \"linear\":\n",
    "    X, y = generate_linear(n = 100)\n",
    "elif generator == \"XOR\":\n",
    "    X, y = generate_XOR_easy()\n",
    "    # every data point in X is a row, [x, y]\n",
    "else:\n",
    "    raise NameError(\"Unknown data generator name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "472ec830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0: accuracy: 66.00%, loss: 64.46156\n",
      "\n",
      "Epochs 100: accuracy: 99.00%, loss: 2.47704\n",
      "\n",
      "Epochs 200: accuracy: 99.00%, loss: 2.43345\n",
      "\n",
      "Epochs 300: accuracy: 96.00%, loss: 11.88112\n",
      "\n",
      "Epochs 400: accuracy: 99.00%, loss: 2.76632\n",
      "\n",
      "Epochs 500: accuracy: 98.00%, loss: 5.55650\n",
      "\n",
      "Epochs 600: accuracy: 99.00%, loss: 2.13096\n",
      "\n",
      "Epochs 700: accuracy: 99.00%, loss: 1.80387\n",
      "\n",
      "Epochs 800: accuracy: 100.00%, loss: 1.94258\n",
      "\n",
      "Epochs 900: accuracy: 99.00%, loss: 1.93513\n",
      "\n",
      "Training finished\n",
      "accuracy: 99.00%, loss: 2.68085\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizers = [Adam_optimizer(), Adam_optimizer(), Adam_optimizer()]\n",
    "network = NN_optimizer(n1, n2, lr, epochs, interval, optimizers = optimizers)\n",
    "network.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4535a2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = np.zeros_like(y)\n",
    "for i in range(X.shape[0]):\n",
    "    pred_y[i, 0] = np.round(network.forward(X[i: (i + 1), :].T))\n",
    "show_result(X, y, pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
